#!/usr/bin/env python3\n\"\"\"\nBuild Motions Mock Implementation\n================================\n\nThis module manages the build_motions directory and provides mock implementations\nfor motion processing, validation, and preparation for the MotionBlendAI pipeline.\nIt handles the intermediate stage between raw seed motions and final demo artifacts.\n\nFeatures:\n---------\n• Motion file processing and validation\n• Format conversion and standardization\n• Quality assessment and filtering\n• Metadata extraction and enrichment\n• Build pipeline management\n• Integration with blend_snn and demo systems\n\nUsage:\n------\n    from project.build_motions.mock_build_motions import MotionBuilder, process_motion_library\n    \n    # Create builder instance\n    builder = MotionBuilder()\n    \n    # Process motion library\n    results = builder.process_seed_motions()\n    \n    # Build specific motions\n    builder.build_motion('Tennis Match Point.fbx')\n\nAuthor: MotionBlendAI Team\nVersion: 1.0.0\n\"\"\"\n\nimport os\nimport json\nimport time\nimport shutil\nimport hashlib\nfrom typing import Dict, List, Any, Optional, Tuple\nfrom dataclasses import dataclass, asdict\nfrom enum import Enum\nimport numpy as np\n\n# Directory paths\nBUILD_DIR = \"/Users/ted/blenderkit_data/MotionBlendAI-1/build\"\nBUILD_MOTIONS_DIR = os.path.join(BUILD_DIR, \"build_motions\")\nSEED_MOTIONS_DIR = \"/Users/ted/blenderkit_data/MotionBlendAI-1/project/seed_motions\"\nBLEND_SNN_DIR = os.path.join(BUILD_DIR, \"blend_snn\")\n\nclass MotionFormat(Enum):\n    \"\"\"Supported motion capture formats.\"\"\"\n    FBX = \"fbx\"\n    TRC = \"trc\"\n    BVH = \"bvh\"\n    GLB = \"glb\"\n    NPY = \"npy\"\n    JSON = \"json\"\n\nclass QualityLevel(Enum):\n    \"\"\"Motion quality assessment levels.\"\"\"\n    EXCELLENT = \"excellent\"\n    GOOD = \"good\"\n    FAIR = \"fair\"\n    POOR = \"poor\"\n\n@dataclass\nclass MotionProcessingConfig:\n    \"\"\"Configuration for motion processing operations.\"\"\"\n    target_fps: int = 30\n    target_format: MotionFormat = MotionFormat.FBX\n    quality_threshold: float = 0.7\n    normalize_scale: bool = True\n    validate_structure: bool = True\n    generate_thumbnails: bool = True\n    extract_features: bool = True\n\n@dataclass\nclass MotionQualityMetrics:\n    \"\"\"Quality assessment metrics for motion data.\"\"\"\n    temporal_consistency: float\n    spatial_accuracy: float\n    joint_coverage: float\n    frame_completeness: float\n    noise_level: float\n    overall_score: float\n    quality_level: QualityLevel\n    issues: List[str]\n\n@dataclass\nclass ProcessedMotion:\n    \"\"\"Represents a processed motion in the build system.\"\"\"\n    motion_id: str\n    source_file: str\n    processed_file: str\n    metadata: Dict[str, Any]\n    quality_metrics: MotionQualityMetrics\n    processing_timestamp: str\n    features: Dict[str, Any]\n    thumbnail_path: Optional[str] = None\n    derivatives: List[str] = None\n\nclass MotionValidator:\n    \"\"\"Validates motion capture data for quality and consistency.\"\"\"\n    \n    def __init__(self, config: MotionProcessingConfig):\n        self.config = config\n    \n    def validate_motion_file(self, filepath: str) -> MotionQualityMetrics:\n        \"\"\"Validate a motion file and assess quality.\"\"\"\n        \n        # Mock validation - in real implementation would analyze actual data\n        filename = os.path.basename(filepath).lower()\n        \n        # Simulate quality assessment based on filename patterns\n        temporal_consistency = self._assess_temporal_consistency(filename)\n        spatial_accuracy = self._assess_spatial_accuracy(filename)\n        joint_coverage = self._assess_joint_coverage(filename)\n        frame_completeness = self._assess_frame_completeness(filename)\n        noise_level = self._assess_noise_level(filename)\n        \n        # Calculate overall score\n        weights = [0.25, 0.25, 0.2, 0.2, 0.1]\n        scores = [temporal_consistency, spatial_accuracy, joint_coverage, \n                 frame_completeness, 1.0 - noise_level]\n        overall_score = sum(w * s for w, s in zip(weights, scores))\n        \n        # Determine quality level\n        if overall_score >= 0.9:\n            quality_level = QualityLevel.EXCELLENT\n        elif overall_score >= 0.75:\n            quality_level = QualityLevel.GOOD\n        elif overall_score >= 0.6:\n            quality_level = QualityLevel.FAIR\n        else:\n            quality_level = QualityLevel.POOR\n        \n        # Identify issues\n        issues = []\n        if temporal_consistency < 0.7:\n            issues.append(\"Temporal inconsistencies detected\")\n        if spatial_accuracy < 0.8:\n            issues.append(\"Spatial accuracy concerns\")\n        if joint_coverage < 0.9:\n            issues.append(\"Incomplete joint coverage\")\n        if frame_completeness < 0.95:\n            issues.append(\"Missing or corrupted frames\")\n        if noise_level > 0.3:\n            issues.append(\"High noise levels\")\n        \n        return MotionQualityMetrics(\n            temporal_consistency=temporal_consistency,\n            spatial_accuracy=spatial_accuracy,\n            joint_coverage=joint_coverage,\n            frame_completeness=frame_completeness,\n            noise_level=noise_level,\n            overall_score=overall_score,\n            quality_level=quality_level,\n            issues=issues\n        )\n    \n    def _assess_temporal_consistency(self, filename: str) -> float:\n        \"\"\"Assess temporal consistency (mock implementation).\"\"\"\n        # Professional motions tend to have better temporal consistency\n        if any(word in filename for word in ['professional', 'tennis', 'kata']):\n            return np.random.uniform(0.85, 0.95)\n        elif any(word in filename for word in ['dance', 'flow']):\n            return np.random.uniform(0.75, 0.9)\n        else:\n            return np.random.uniform(0.6, 0.85)\n    \n    def _assess_spatial_accuracy(self, filename: str) -> float:\n        \"\"\"Assess spatial accuracy (mock implementation).\"\"\"\n        # Motion capture quality varies by source\n        if 'mixamo' in filename:\n            return np.random.uniform(0.8, 0.95)  # Good quality\n        elif any(word in filename for word in ['spell', 'magic']):\n            return np.random.uniform(0.7, 0.85)  # Fantasy motions may be stylized\n        else:\n            return np.random.uniform(0.75, 0.9)\n    \n    def _assess_joint_coverage(self, filename: str) -> float:\n        \"\"\"Assess joint coverage completeness (mock implementation).\"\"\"\n        # Most modern mocap has good joint coverage\n        return np.random.uniform(0.85, 0.98)\n    \n    def _assess_frame_completeness(self, filename: str) -> float:\n        \"\"\"Assess frame data completeness (mock implementation).\"\"\"\n        # Usually high for professional captures\n        return np.random.uniform(0.9, 0.99)\n    \n    def _assess_noise_level(self, filename: str) -> float:\n        \"\"\"Assess noise level in motion data (mock implementation).\"\"\"\n        # Lower noise for professional captures\n        if any(word in filename for word in ['professional', 'olympic']):\n            return np.random.uniform(0.05, 0.15)\n        else:\n            return np.random.uniform(0.1, 0.25)\n\nclass MotionFeatureExtractor:\n    \"\"\"Extracts features and characteristics from motion data.\"\"\"\n    \n    def extract_features(self, filepath: str, quality_metrics: MotionQualityMetrics) -> Dict[str, Any]:\n        \"\"\"Extract motion features for analysis and search.\"\"\"\n        \n        filename = os.path.basename(filepath)\n        name_lower = filename.lower()\n        \n        # Extract semantic features\n        features = {\n            'motion_type': self._classify_motion_type(name_lower),\n            'energy_level': self._estimate_energy_level(name_lower),\n            'complexity_score': self._estimate_complexity(name_lower),\n            'dominant_body_parts': self._identify_body_parts(name_lower),\n            'rhythm_pattern': self._analyze_rhythm(name_lower),\n            'spatial_extent': self._estimate_spatial_extent(name_lower),\n            'interaction_type': self._classify_interaction(name_lower),\n            'emotional_content': self._analyze_emotion(name_lower),\n            'technical_difficulty': self._assess_difficulty(name_lower),\n            'style_characteristics': self._extract_style_features(name_lower)\n        }\n        \n        # Add quality-derived features\n        features['quality_score'] = quality_metrics.overall_score\n        features['reliability_score'] = 1.0 - quality_metrics.noise_level\n        features['completeness_score'] = quality_metrics.frame_completeness\n        \n        # Generate motion signature (hash-based)\n        features['motion_signature'] = self._generate_motion_signature(filepath, features)\n        \n        return features\n    \n    def _classify_motion_type(self, name: str) -> str:\n        \"\"\"Classify the type of motion.\"\"\"\n        if any(word in name for word in ['dance', 'dancing']):\n            return 'dance'\n        elif any(word in name for word in ['punch', 'kick', 'fight', 'martial']):\n            return 'combat'\n        elif any(word in name for word in ['tennis', 'sport', 'match']):\n            return 'athletic'\n        elif any(word in name for word in ['walk', 'run', 'locomotion']):\n            return 'locomotion'\n        elif any(word in name for word in ['spell', 'magic']):\n            return 'gesture'\n        else:\n            return 'general'\n    \n    def _estimate_energy_level(self, name: str) -> float:\n        \"\"\"Estimate motion energy level (0-1).\"\"\"\n        if any(word in name for word in ['sprint', 'explosive', 'high']):\n            return np.random.uniform(0.8, 1.0)\n        elif any(word in name for word in ['dance', 'dynamic']):\n            return np.random.uniform(0.6, 0.85)\n        elif any(word in name for word in ['walk', 'gentle', 'slow']):\n            return np.random.uniform(0.2, 0.5)\n        else:\n            return np.random.uniform(0.4, 0.7)\n    \n    def _estimate_complexity(self, name: str) -> float:\n        \"\"\"Estimate motion complexity (0-1).\"\"\"\n        if any(word in name for word in ['kata', 'complex', 'routine']):\n            return np.random.uniform(0.8, 0.95)\n        elif any(word in name for word in ['dance', 'martial']):\n            return np.random.uniform(0.6, 0.8)\n        elif any(word in name for word in ['basic', 'simple']):\n            return np.random.uniform(0.2, 0.4)\n        else:\n            return np.random.uniform(0.4, 0.7)\n    \n    def _identify_body_parts(self, name: str) -> List[str]:\n        \"\"\"Identify dominant body parts in motion.\"\"\"\n        parts = []\n        if any(word in name for word in ['kick', 'leg']):\n            parts.extend(['legs', 'lower_body'])\n        if any(word in name for word in ['punch', 'arm', 'hand']):\n            parts.extend(['arms', 'upper_body'])\n        if any(word in name for word in ['dance', 'full']):\n            parts.extend(['full_body', 'core'])\n        if any(word in name for word in ['head', 'neck']):\n            parts.append('head')\n        \n        return list(set(parts)) if parts else ['full_body']\n    \n    def _analyze_rhythm(self, name: str) -> Dict[str, Any]:\n        \"\"\"Analyze rhythmic characteristics.\"\"\"\n        if 'dance' in name:\n            return {\n                'has_rhythm': True,\n                'rhythm_type': 'musical',\n                'tempo': 'medium' if 'slow' not in name else 'slow'\n            }\n        elif any(word in name for word in ['martial', 'kata']):\n            return {\n                'has_rhythm': True,\n                'rhythm_type': 'controlled',\n                'tempo': 'variable'\n            }\n        else:\n            return {\n                'has_rhythm': False,\n                'rhythm_type': 'none',\n                'tempo': 'natural'\n            }\n    \n    def _estimate_spatial_extent(self, name: str) -> Dict[str, float]:\n        \"\"\"Estimate spatial requirements.\"\"\"\n        if any(word in name for word in ['tennis', 'sport']):\n            return {'width': 0.8, 'depth': 0.9, 'height': 0.7}\n        elif 'dance' in name:\n            return {'width': 0.6, 'depth': 0.6, 'height': 0.5}\n        elif any(word in name for word in ['walk', 'run']):\n            return {'width': 0.4, 'depth': 1.0, 'height': 0.3}\n        else:\n            return {'width': 0.5, 'depth': 0.5, 'height': 0.4}\n    \n    def _classify_interaction(self, name: str) -> str:\n        \"\"\"Classify interaction type.\"\"\"\n        if any(word in name for word in ['tennis', 'match']):\n            return 'object_interaction'\n        elif any(word in name for word in ['dance', 'partner']):\n            return 'partner_interaction'\n        elif any(word in name for word in ['solo', 'individual']):\n            return 'solo'\n        else:\n            return 'solo'\n    \n    def _analyze_emotion(self, name: str) -> Dict[str, Any]:\n        \"\"\"Analyze emotional content.\"\"\"\n        if 'angry' in name:\n            return {'primary_emotion': 'anger', 'intensity': 0.8}\n        elif 'dance' in name:\n            return {'primary_emotion': 'joy', 'intensity': 0.7}\n        elif any(word in name for word in ['martial', 'fight']):\n            return {'primary_emotion': 'determination', 'intensity': 0.6}\n        else:\n            return {'primary_emotion': 'neutral', 'intensity': 0.3}\n    \n    def _assess_difficulty(self, name: str) -> float:\n        \"\"\"Assess technical difficulty (0-1).\"\"\"\n        if any(word in name for word in ['professional', 'expert']):\n            return np.random.uniform(0.8, 0.95)\n        elif any(word in name for word in ['advanced', 'complex']):\n            return np.random.uniform(0.7, 0.85)\n        elif any(word in name for word in ['basic', 'simple']):\n            return np.random.uniform(0.2, 0.4)\n        else:\n            return np.random.uniform(0.4, 0.7)\n    \n    def _extract_style_features(self, name: str) -> Dict[str, Any]:\n        \"\"\"Extract style characteristics.\"\"\"\n        style = {}\n        \n        if 'mixamo' in name:\n            style['source'] = 'mixamo'\n            style['style_quality'] = 'commercial'\n        \n        if any(word in name for word in ['hip', 'hop', 'urban']):\n            style['genre'] = 'hip_hop'\n        elif any(word in name for word in ['classical', 'traditional']):\n            style['genre'] = 'classical'\n        elif any(word in name for word in ['contemporary', 'modern']):\n            style['genre'] = 'contemporary'\n        \n        return style\n    \n    def _generate_motion_signature(self, filepath: str, features: Dict[str, Any]) -> str:\n        \"\"\"Generate unique motion signature.\"\"\"\n        # Create signature from filename and key features\n        signature_data = f\"{os.path.basename(filepath)}_{features['motion_type']}_{features['energy_level']:.2f}\"\n        return hashlib.md5(signature_data.encode()).hexdigest()[:16]\n\nclass MotionBuilder:\n    \"\"\"Main builder class for processing motions.\"\"\"\n    \n    def __init__(self, config: MotionProcessingConfig = None):\n        self.config = config or MotionProcessingConfig()\n        self.validator = MotionValidator(self.config)\n        self.feature_extractor = MotionFeatureExtractor()\n        \n        # Ensure directories exist\n        os.makedirs(BUILD_MOTIONS_DIR, exist_ok=True)\n        \n        # Processing state\n        self.processed_motions: List[ProcessedMotion] = []\n        self.processing_log: List[Dict[str, Any]] = []\n    \n    def process_seed_motions(self) -> Dict[str, Any]:\n        \"\"\"Process all seed motions into build_motions directory.\"\"\"\n        \n        if not os.path.exists(SEED_MOTIONS_DIR):\n            return {'error': 'Seed motions directory not found'}\n        \n        # Get all motion files\n        motion_files = []\n        for file in os.listdir(SEED_MOTIONS_DIR):\n            if file.lower().endswith(('.fbx', '.trc', '.bvh', '.glb', '.npy')):\n                motion_files.append(file)\n        \n        results = {\n            'total_files': len(motion_files),\n            'processed': 0,\n            'failed': 0,\n            'skipped': 0,\n            'processing_details': []\n        }\n        \n        for filename in motion_files:\n            try:\n                source_path = os.path.join(SEED_MOTIONS_DIR, filename)\n                processed_motion = self.build_motion(source_path)\n                \n                if processed_motion:\n                    results['processed'] += 1\n                    results['processing_details'].append({\n                        'file': filename,\n                        'status': 'success',\n                        'quality': processed_motion.quality_metrics.quality_level.value,\n                        'output': processed_motion.processed_file\n                    })\n                else:\n                    results['skipped'] += 1\n                    results['processing_details'].append({\n                        'file': filename,\n                        'status': 'skipped',\n                        'reason': 'Below quality threshold'\n                    })\n                    \n            except Exception as e:\n                results['failed'] += 1\n                results['processing_details'].append({\n                    'file': filename,\n                    'status': 'failed',\n                    'error': str(e)\n                })\n        \n        # Save processing summary\n        self.save_processing_summary(results)\n        \n        return results\n    \n    def build_motion(self, source_path: str) -> Optional[ProcessedMotion]:\n        \"\"\"Process a single motion file.\"\"\"\n        \n        filename = os.path.basename(source_path)\n        motion_id = f\"build_{hashlib.md5(filename.encode()).hexdigest()[:8]}\"\n        \n        # Validate motion\n        quality_metrics = self.validator.validate_motion_file(source_path)\n        \n        # Check quality threshold\n        if quality_metrics.overall_score < self.config.quality_threshold:\n            self.processing_log.append({\n                'motion_id': motion_id,\n                'filename': filename,\n                'status': 'rejected',\n                'reason': f'Quality score {quality_metrics.overall_score:.2f} below threshold {self.config.quality_threshold}'\n            })\n            return None\n        \n        # Extract features\n        features = self.feature_extractor.extract_features(source_path, quality_metrics)\n        \n        # Create processed file path\n        base_name = os.path.splitext(filename)[0]\n        processed_filename = f\"{base_name}_processed.{self.config.target_format.value}\"\n        processed_path = os.path.join(BUILD_MOTIONS_DIR, processed_filename)\n        \n        # \"Process\" file (mock - just copy for now)\n        shutil.copy2(source_path, processed_path)\n        \n        # Generate metadata\n        metadata = {\n            'original_file': filename,\n            'processing_config': asdict(self.config),\n            'processing_timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ'),\n            'file_size': os.path.getsize(source_path),\n            'estimated_duration': features.get('estimated_duration', 5.0),\n            'motion_category': features['motion_type'],\n            'format_converted': source_path.endswith('.fbx') != processed_path.endswith('.fbx')\n        }\n        \n        # Create processed motion object\n        processed_motion = ProcessedMotion(\n            motion_id=motion_id,\n            source_file=source_path,\n            processed_file=processed_path,\n            metadata=metadata,\n            quality_metrics=quality_metrics,\n            processing_timestamp=metadata['processing_timestamp'],\n            features=features,\n            derivatives=[]\n        )\n        \n        # Generate thumbnail (mock)\n        if self.config.generate_thumbnails:\n            thumbnail_path = self.generate_thumbnail(processed_motion)\n            processed_motion.thumbnail_path = thumbnail_path\n        \n        # Save motion metadata\n        self.save_motion_metadata(processed_motion)\n        \n        self.processed_motions.append(processed_motion)\n        \n        self.processing_log.append({\n            'motion_id': motion_id,\n            'filename': filename,\n            'status': 'success',\n            'quality_score': quality_metrics.overall_score,\n            'features_extracted': len(features)\n        })\n        \n        return processed_motion\n    \n    def generate_thumbnail(self, processed_motion: ProcessedMotion) -> str:\n        \"\"\"Generate motion thumbnail (mock implementation).\"\"\"\n        \n        base_name = os.path.splitext(os.path.basename(processed_motion.processed_file))[0]\n        thumbnail_filename = f\"{base_name}_thumbnail.json\"\n        thumbnail_path = os.path.join(BUILD_MOTIONS_DIR, thumbnail_filename)\n        \n        # Mock thumbnail data (key poses, timing, etc.)\n        thumbnail_data = {\n            'motion_id': processed_motion.motion_id,\n            'key_poses': [\n                {'frame': 0, 'pose_type': 'start', 'energy': 0.3},\n                {'frame': 30, 'pose_type': 'mid', 'energy': 0.7},\n                {'frame': 60, 'pose_type': 'end', 'energy': 0.2}\n            ],\n            'motion_curve': [0.3, 0.5, 0.7, 0.6, 0.4, 0.2],\n            'dominant_features': processed_motion.features['dominant_body_parts'],\n            'preview_frames': [0, 15, 30, 45, 60]\n        }\n        \n        with open(thumbnail_path, 'w') as f:\n            json.dump(thumbnail_data, f, indent=2)\n        \n        return thumbnail_path\n    \n    def save_motion_metadata(self, processed_motion: ProcessedMotion) -> None:\n        \"\"\"Save detailed motion metadata.\"\"\"\n        \n        base_name = os.path.splitext(os.path.basename(processed_motion.processed_file))[0]\n        metadata_filename = f\"{base_name}_metadata.json\"\n        metadata_path = os.path.join(BUILD_MOTIONS_DIR, metadata_filename)\n        \n        metadata = {\n            'motion_id': processed_motion.motion_id,\n            'source_file': processed_motion.source_file,\n            'processed_file': processed_motion.processed_file,\n            'metadata': processed_motion.metadata,\n            'quality_metrics': asdict(processed_motion.quality_metrics),\n            'features': processed_motion.features,\n            'processing_timestamp': processed_motion.processing_timestamp,\n            'thumbnail_path': processed_motion.thumbnail_path\n        }\n        \n        with open(metadata_path, 'w') as f:\n            json.dump(metadata, f, indent=2)\n    \n    def save_processing_summary(self, results: Dict[str, Any]) -> None:\n        \"\"\"Save processing summary report.\"\"\"\n        \n        summary_path = os.path.join(BUILD_MOTIONS_DIR, \"processing_summary.json\")\n        \n        summary = {\n            'processing_timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ'),\n            'config': asdict(self.config),\n            'results': results,\n            'processing_log': self.processing_log,\n            'total_processed_motions': len(self.processed_motions)\n        }\n        \n        with open(summary_path, 'w') as f:\n            json.dump(summary, f, indent=2)\n    \n    def get_build_statistics(self) -> Dict[str, Any]:\n        \"\"\"Get comprehensive build statistics.\"\"\"\n        \n        if not os.path.exists(BUILD_MOTIONS_DIR):\n            return {'error': 'Build motions directory not found'}\n        \n        # Count files\n        all_files = os.listdir(BUILD_MOTIONS_DIR)\n        motion_files = [f for f in all_files if any(f.endswith(ext) for ext in ['.fbx', '.trc', '.bvh', '.glb'])]\n        metadata_files = [f for f in all_files if f.endswith('_metadata.json')]\n        thumbnail_files = [f for f in all_files if f.endswith('_thumbnail.json')]\n        \n        # Analyze quality distribution\n        quality_distribution = {'excellent': 0, 'good': 0, 'fair': 0, 'poor': 0}\n        \n        for metadata_file in metadata_files:\n            try:\n                with open(os.path.join(BUILD_MOTIONS_DIR, metadata_file), 'r') as f:\n                    metadata = json.load(f)\n                    quality_level = metadata.get('quality_metrics', {}).get('quality_level', 'unknown')\n                    if quality_level in quality_distribution:\n                        quality_distribution[quality_level] += 1\n            except:\n                pass\n        \n        return {\n            'total_motion_files': len(motion_files),\n            'metadata_files': len(metadata_files),\n            'thumbnail_files': len(thumbnail_files),\n            'quality_distribution': quality_distribution,\n            'directory_size_mb': self._calculate_directory_size(BUILD_MOTIONS_DIR),\n            'last_processing': self._get_last_processing_time(),\n            'build_motions_directory': BUILD_MOTIONS_DIR\n        }\n    \n    def _calculate_directory_size(self, directory: str) -> float:\n        \"\"\"Calculate total directory size in MB.\"\"\"\n        total_size = 0\n        for dirpath, dirnames, filenames in os.walk(directory):\n            for filename in filenames:\n                filepath = os.path.join(dirpath, filename)\n                total_size += os.path.getsize(filepath)\n        return round(total_size / (1024 * 1024), 2)\n    \n    def _get_last_processing_time(self) -> Optional[str]:\n        \"\"\"Get timestamp of last processing operation.\"\"\"\n        summary_path = os.path.join(BUILD_MOTIONS_DIR, \"processing_summary.json\")\n        if os.path.exists(summary_path):\n            try:\n                with open(summary_path, 'r') as f:\n                    summary = json.load(f)\n                    return summary.get('processing_timestamp')\n            except:\n                pass\n        return None\n\n# Convenience functions\ndef process_motion_library(config: MotionProcessingConfig = None) -> Dict[str, Any]:\n    \"\"\"High-level function to process the entire motion library.\"\"\"\n    builder = MotionBuilder(config)\n    return builder.process_seed_motions()\n\ndef get_build_motions_summary() -> Dict[str, Any]:\n    \"\"\"Get summary of build_motions directory.\"\"\"\n    builder = MotionBuilder()\n    return builder.get_build_statistics()\n\nif __name__ == '__main__':\n    # Demo the build motions system\n    print(\"🏗️ MotionBlendAI Build Motions System\")\n    print(\"=\" * 45)\n    \n    # Create builder with custom config\n    config = MotionProcessingConfig(\n        quality_threshold=0.6,\n        generate_thumbnails=True,\n        extract_features=True\n    )\n    \n    builder = MotionBuilder(config)\n    \n    print(f\"\\n🔧 Processing seed motions with config:\")\n    print(f\"  Quality threshold: {config.quality_threshold}\")\n    print(f\"  Target format: {config.target_format.value}\")\n    print(f\"  Generate thumbnails: {config.generate_thumbnails}\")\n    \n    # Process motions\n    results = builder.process_seed_motions()\n    \n    print(f\"\\n📊 Processing Results:\")\n    print(f\"  Total files: {results['total_files']}\")\n    print(f\"  Processed: {results['processed']}\")\n    print(f\"  Failed: {results['failed']}\")\n    print(f\"  Skipped: {results['skipped']}\")\n    \n    # Show statistics\n    stats = builder.get_build_statistics()\n    print(f\"\\n📈 Build Statistics:\")\n    for key, value in stats.items():\n        if key != 'quality_distribution':\n            print(f\"  {key}: {value}\")\n    \n    if 'quality_distribution' in stats:\n        print(f\"  Quality distribution:\")\n        for quality, count in stats['quality_distribution'].items():\n            print(f\"    {quality}: {count}\")\n