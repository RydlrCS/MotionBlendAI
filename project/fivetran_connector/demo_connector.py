#!/usr/bin/env python3\n\"\"\"\nSimple demonstration of MotionBlend AI Fivetran Connector capabilities\n\"\"\"\n\nimport json\nimport os\nfrom pathlib import Path\nfrom datetime import datetime\n\ndef demo_fivetran_connector():\n    \"\"\"Demonstrate what the Fivetran connector would extract from the workspace.\"\"\"\n    \n    print(\"🎬 MotionBlend AI Fivetran Connector Demo\")\n    print(\"========================================\\n\")\n    \n    workspace = Path(\"/Users/ted/blenderkit_data/MotionBlendAI-1\")\n    \n    if not workspace.exists():\n        print(f\"❌ Workspace not found: {workspace}\")\n        return\n    \n    print(f\"📂 Scanning workspace: {workspace}\\n\")\n    \n    # Simulate motion sequence discovery\n    motion_sequences = []\n    search_paths = [\n        workspace / 'build' / 'build_motions',\n        workspace / 'build' / 'blend_snn',\n        workspace / 'project' / 'seed_motions',\n    ]\n    \n    for search_path in search_paths:\n        if search_path.exists():\n            print(f\"🔍 Scanning: {search_path.relative_to(workspace)}\")\n            \n            for pattern in ['*.glb', '*.trc', '*.npy', '*.fbx']:\n                files = list(search_path.glob(pattern))\n                for file_path in files:\n                    stat = file_path.stat()\n                    \n                    # Simulate metadata extraction\n                    sequence = {\n                        \"sequence_id\": str(file_path.relative_to(workspace)).replace('/', '_'),\n                        \"name\": file_path.stem,\n                        \"file_format\": file_path.suffix.upper().lstrip('.'),\n                        \"file_size_bytes\": stat.st_size,\n                        \"file_path\": str(file_path.relative_to(workspace)),\n                        \"discovered_at\": datetime.now().isoformat()\n                    }\n                    \n                    motion_sequences.append(sequence)\n                    size_mb = stat.st_size / (1024 * 1024)\n                    print(f\"   📄 {file_path.name} ({size_mb:.1f} MB)\")\n    \n    # Simulate blend job discovery\n    blend_jobs = []\n    blend_path = workspace / 'build' / 'blend_snn'\n    if blend_path.exists():\n        print(f\"\\n🔍 Scanning blend results: {blend_path.relative_to(workspace)}\")\n        \n        for blend_file in blend_path.glob('blend_*.npy'):\n            stat = blend_file.stat()\n            \n            # Parse blend filename\n            filename_parts = blend_file.stem.split('_')\n            if len(filename_parts) >= 3:\n                seq_a = '_'.join(filename_parts[1:-1])\n                seq_b = filename_parts[-1]\n            else:\n                seq_a = 'unknown'\n                seq_b = 'unknown'\n            \n            job = {\n                \"job_id\": blend_file.stem,\n                \"sequence_a_id\": seq_a,\n                \"sequence_b_id\": seq_b,\n                \"status\": \"completed\",\n                \"output_file_path\": str(blend_file.relative_to(workspace)),\n                \"output_file_size_bytes\": stat.st_size,\n                \"completed_at\": datetime.fromtimestamp(stat.st_mtime).isoformat()\n            }\n            \n            blend_jobs.append(job)\n            size_kb = stat.st_size / 1024\n            print(f\"   🎯 {blend_file.name} ({size_kb:.1f} KB) - {seq_a} + {seq_b}\")\n    \n    # Simulate artifact discovery\n    artifacts = []\n    artifact_path = workspace / 'build' / 'demo_artifacts'\n    if artifact_path.exists():\n        print(f\"\\n🔍 Scanning artifacts: {artifact_path.relative_to(workspace)}\")\n        \n        for artifact_file in artifact_path.iterdir():\n            if artifact_file.is_file():\n                stat = artifact_file.stat()\n                \n                # Determine artifact type\n                if artifact_file.suffix == '.json':\n                    artifact_type = 'manifest'\n                elif artifact_file.suffix == '.log':\n                    artifact_type = 'log'\n                elif artifact_file.suffix == '.npy':\n                    artifact_type = 'blend_result'\n                else:\n                    artifact_type = 'unknown'\n                \n                artifact = {\n                    \"artifact_id\": str(artifact_file.relative_to(workspace)).replace('/', '_'),\n                    \"artifact_type\": artifact_type,\n                    \"file_name\": artifact_file.name,\n                    \"file_size_bytes\": stat.st_size,\n                    \"created_at\": datetime.fromtimestamp(stat.st_ctime).isoformat()\n                }\n                \n                artifacts.append(artifact)\n                size_b = stat.st_size\n                print(f\"   📦 {artifact_file.name} ({size_b} B) - {artifact_type}\")\n    \n    # Summary\n    print(f\"\\n📊 Discovery Summary:\")\n    print(f\"   🎬 Motion Sequences: {len(motion_sequences)}\")\n    print(f\"   🎯 Blend Jobs: {len(blend_jobs)}\")\n    print(f\"   📦 Artifacts: {len(artifacts)}\")\n    \n    # Show what would be synced to Fivetran\n    print(f\"\\n🚀 Fivetran Data Warehouse Tables:\")\n    \n    tables = {\n        \"motion_sequences\": motion_sequences,\n        \"blend_jobs\": blend_jobs, \n        \"processing_artifacts\": artifacts\n    }\n    \n    for table_name, records in tables.items():\n        print(f\"\\n📋 Table: {table_name} ({len(records)} records)\")\n        \n        if records:\n            # Show sample record structure\n            sample = records[0]\n            print(f\"   Sample record keys: {list(sample.keys())}\")\n            \n            # Show first few records\n            for i, record in enumerate(records[:3]):\n                name = record.get('name', record.get('job_id', record.get('file_name', 'unknown')))\n                print(f\"   - {name}\")\n            \n            if len(records) > 3:\n                print(f\"   ... and {len(records) - 3} more\")\n    \n    print(f\"\\n✅ Connector would stream all this data to your data warehouse!\")\n    print(f\"📈 Enable analytics on motion processing, blend performance, and user behavior.\")\n    \n    # Sample analytics queries\n    print(f\"\\n📊 Example Analytics Queries:\")\n    print(f\"   • Most popular motion sequences for blending\")\n    print(f\"   • Blend job success rates and processing times\")\n    print(f\"   • Storage usage trends and file growth\")\n    print(f\"   • Motion catalog completeness and metadata quality\")\n    \n    return tables\n\n\nif __name__ == \"__main__\":\n    demo_fivetran_connector()\n